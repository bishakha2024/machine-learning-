{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d9dbf9-48a3-478f-9461-b57850e5d4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Extractor</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.675332</td>\n",
       "      <td>0.713054</td>\n",
       "      <td>0.675332</td>\n",
       "      <td>0.656883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.687798</td>\n",
       "      <td>0.698715</td>\n",
       "      <td>0.687798</td>\n",
       "      <td>0.690207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.555438</td>\n",
       "      <td>0.596149</td>\n",
       "      <td>0.555438</td>\n",
       "      <td>0.565274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.481167</td>\n",
       "      <td>0.492798</td>\n",
       "      <td>0.481167</td>\n",
       "      <td>0.483369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TF-IDFVectorizer</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.722281</td>\n",
       "      <td>0.764252</td>\n",
       "      <td>0.722281</td>\n",
       "      <td>0.712480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TF-IDFVectorizer</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.733156</td>\n",
       "      <td>0.743674</td>\n",
       "      <td>0.733156</td>\n",
       "      <td>0.732105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TF-IDFVectorizer</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.737135</td>\n",
       "      <td>0.752507</td>\n",
       "      <td>0.737135</td>\n",
       "      <td>0.739265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TF-IDFVectorizer</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.467109</td>\n",
       "      <td>0.477918</td>\n",
       "      <td>0.467109</td>\n",
       "      <td>0.469103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.459682</td>\n",
       "      <td>0.457593</td>\n",
       "      <td>0.459682</td>\n",
       "      <td>0.453032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.455703</td>\n",
       "      <td>0.457347</td>\n",
       "      <td>0.455703</td>\n",
       "      <td>0.451653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.234483</td>\n",
       "      <td>0.238299</td>\n",
       "      <td>0.234483</td>\n",
       "      <td>0.235450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.579841</td>\n",
       "      <td>0.586098</td>\n",
       "      <td>0.579841</td>\n",
       "      <td>0.578514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.563395</td>\n",
       "      <td>0.579802</td>\n",
       "      <td>0.563395</td>\n",
       "      <td>0.565344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.205570</td>\n",
       "      <td>0.208490</td>\n",
       "      <td>0.205570</td>\n",
       "      <td>0.206401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Extractor          Classifier  Accuracy  Precision    Recall  \\\n",
       "0    CountVectorizer       MultinomialNB  0.675332   0.713054  0.675332   \n",
       "1    CountVectorizer  LogisticRegression  0.687798   0.698715  0.687798   \n",
       "2    CountVectorizer                 SVM  0.555438   0.596149  0.555438   \n",
       "3    CountVectorizer        DecisionTree  0.481167   0.492798  0.481167   \n",
       "4   TF-IDFVectorizer       MultinomialNB  0.722281   0.764252  0.722281   \n",
       "5   TF-IDFVectorizer  LogisticRegression  0.733156   0.743674  0.733156   \n",
       "6   TF-IDFVectorizer                 SVM  0.737135   0.752507  0.737135   \n",
       "7   TF-IDFVectorizer        DecisionTree  0.467109   0.477918  0.467109   \n",
       "8           Word2Vec  LogisticRegression  0.459682   0.457593  0.459682   \n",
       "9           Word2Vec                 SVM  0.455703   0.457347  0.455703   \n",
       "10          Word2Vec        DecisionTree  0.234483   0.238299  0.234483   \n",
       "11           Doc2Vec  LogisticRegression  0.579841   0.586098  0.579841   \n",
       "12           Doc2Vec                 SVM  0.563395   0.579802  0.563395   \n",
       "13           Doc2Vec        DecisionTree  0.205570   0.208490  0.205570   \n",
       "\n",
       "    F1-Score  \n",
       "0   0.656883  \n",
       "1   0.690207  \n",
       "2   0.565274  \n",
       "3   0.483369  \n",
       "4   0.712480  \n",
       "5   0.732105  \n",
       "6   0.739265  \n",
       "7   0.469103  \n",
       "8   0.453032  \n",
       "9   0.451653  \n",
       "10  0.235450  \n",
       "11  0.578514  \n",
       "12  0.565344  \n",
       "13  0.206401  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "categories = None  # Use all categories\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define feature extractors\n",
    "vectorizers = {\n",
    "    \"CountVectorizer\": CountVectorizer(stop_words='english'),\n",
    "    \"TF-IDFVectorizer\": TfidfVectorizer(stop_words='english')\n",
    "}\n",
    "\n",
    "# Train Word2Vec model\n",
    "train_tokenized = [gensim.utils.simple_preprocess(text) for text in X_train]\n",
    "test_tokenized = [gensim.utils.simple_preprocess(text) for text in X_test]\n",
    "w2v_model = Word2Vec(sentences=train_tokenized, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "def vectorize_text_w2v(text, model, vector_size=100):\n",
    "    vectors = [model.wv[word] for word in gensim.utils.simple_preprocess(text) if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)\n",
    "\n",
    "X_train_w2v = np.array([vectorize_text_w2v(text, w2v_model) for text in X_train])\n",
    "X_test_w2v = np.array([vectorize_text_w2v(text, w2v_model) for text in X_test])\n",
    "\n",
    "# Train Doc2Vec model\n",
    "td_train = [TaggedDocument(words=gensim.utils.simple_preprocess(text), tags=[i]) for i, text in enumerate(X_train)]\n",
    "d2v_model = Doc2Vec(td_train, vector_size=100, window=5, min_count=2, workers=4, epochs=20)\n",
    "\n",
    "def vectorize_text_d2v(text, model):\n",
    "    return model.infer_vector(gensim.utils.simple_preprocess(text))\n",
    "\n",
    "X_train_d2v = np.array([vectorize_text_d2v(text, d2v_model) for text in X_train])\n",
    "X_test_d2v = np.array([vectorize_text_d2v(text, d2v_model) for text in X_test])\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(kernel='linear'),\n",
    "    \"DecisionTree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Benchmarking results\n",
    "results = []\n",
    "\n",
    "# Evaluate feature extractors with classifiers\n",
    "for vec_name, vectorizer in vectorizers.items():\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        model = make_pipeline(vectorizer, clf)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        results.append([vec_name, clf_name, accuracy, precision, recall, f1])\n",
    "\n",
    "# Evaluate Word2Vec and Doc2Vec\n",
    "for vec_name, (X_train_feat, X_test_feat) in zip([\"Word2Vec\", \"Doc2Vec\"], [(X_train_w2v, X_test_w2v), (X_train_d2v, X_test_d2v)]):\n",
    "    for clf_name, clf in {\"LogisticRegression\": LogisticRegression(max_iter=1000), \"SVM\": SVC(kernel='linear'), \"DecisionTree\": DecisionTreeClassifier()}.items():\n",
    "        clf.fit(X_train_feat, y_train)\n",
    "        y_pred = clf.predict(X_test_feat)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        results.append([vec_name, clf_name, accuracy, precision, recall, f1])\n",
    "\n",
    "# Save results in a file\n",
    "df_results = pd.DataFrame(results, columns=[\"Feature Extractor\", \"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "df_results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd2a6784-c1f1-4f71-9c92-3db6057bc24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Applications/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Applications/anaconda3/lib/python3.12/site-packages (from python-docx) (4.11.0)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca43974-09db-4cc2-ab52-5713014b59ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully at bIsHaKhA_Task0_Text_Classification.doc\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Data to be written\n",
    "data = [\n",
    "    [\"Feature Extractor\", \"Algorithm\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"],\n",
    "    [\"CountVectorizer\", \"MultinomialNB\", 0.675332, 0.713054, 0.675332, 0.656883],\n",
    "    [\"CountVectorizer\", \"LogisticRegression\", 0.687798, 0.698715, 0.687798, 0.690207],\n",
    "    [\"CountVectorizer\", \"SVM\", 0.555438, 0.596149, 0.555438, 0.565274],\n",
    "    [\"CountVectorizer\", \"DecisionTree\", 0.481167, 0.492798, 0.481167, 0.483369],\n",
    "    [\"TF-IDFVectorizer\", \"MultinomialNB\", 0.722281, 0.764252, 0.722281, 0.712480],\n",
    "    [\"TF-IDFVectorizer\", \"LogisticRegression\", 0.733156, 0.743674, 0.733156, 0.732105],\n",
    "    [\"TF-IDFVectorizer\", \"SVM\", 0.737135, 0.752507, 0.737135, 0.739265],  # Best Model\n",
    "    [\"TF-IDFVectorizer\", \"DecisionTree\", 0.467109, 0.477918, 0.467109, 0.469103],\n",
    "    [\"Word2Vec\", \"LogisticRegression\", 0.459682, 0.457593, 0.459682, 0.453032],\n",
    "    [\"Word2Vec\", \"SVM\", 0.455703, 0.457347, 0.455703, 0.451653],\n",
    "    [\"Word2Vec\", \"DecisionTree\", 0.234483, 0.238299, 0.234483, 0.235450],\n",
    "    [\"Doc2Vec\", \"LogisticRegression\", 0.579841, 0.586098, 0.579841, 0.578514],\n",
    "    [\"Doc2Vec\", \"SVM\", 0.563395, 0.579802, 0.563395, 0.565344],\n",
    "    [\"Doc2Vec\", \"DecisionTree\", 0.205570, 0.208490, 0.205570, 0.206401],\n",
    "]\n",
    "\n",
    "# Identify best model (highest accuracy)\n",
    "best_model = max(data[1:], key=lambda x: x[2])  # Highest accuracy\n",
    "\n",
    "# Create a Document\n",
    "doc = Document()\n",
    "doc.add_heading(\"Benchmarking Text Classification Algorithms\", level=1)\n",
    "\n",
    "# Add table\n",
    "table = doc.add_table(rows=len(data), cols=len(data[0]))\n",
    "table.style = \"Table Grid\"\n",
    "\n",
    "# Populate the table\n",
    "for row_idx, row_data in enumerate(data):\n",
    "    for col_idx, value in enumerate(row_data):\n",
    "        cell = table.cell(row_idx, col_idx)\n",
    "        cell.text = str(value)\n",
    "        # Highlight the best model\n",
    "        if row_idx > 0 and row_data == best_model:\n",
    "            cell.paragraphs[0].runs[0].bold = True\n",
    "\n",
    "# Save the document\n",
    "\n",
    "file_path = \"bIsHaKhA_Task0_Text_Classification.doc\"  \n",
    "doc.save(file_path)\n",
    "print(f\"File saved successfully at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28f4ed-faf3-49b6-9e2b-9b4098bd55db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
